{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c5452",
   "metadata": {},
   "source": [
    "**ISCTE - Lisbon University Institute**\n",
    "\n",
    "Master Degree in Artificial Intelligence\n",
    "Advanced Machine Learning\n",
    "2025/2026 - 1st semester\n",
    "\n",
    "*Project Assignement*\n",
    "Version 1.0 (2025-11-18)\n",
    "\n",
    "    This work must be carried individually or in pairs of 2 students (recommended).\n",
    "    Deadline: Saturday, December 6, until 11:59 PM.\n",
    "    The project presentation will take place on December 9, during class time.\n",
    "\n",
    "*Part 1 – POS Tagging*\n",
    "The goal of this assignment is to develop and compare models for Part-of-Speech (POS) tagging using two different deep learning architectures:\n",
    "\n",
    "    *LSTM-based models*\n",
    "    *Pre-trained transformer-based models*\n",
    "\n",
    "Students will train or fine-tune, evaluate, and analyze the performance of these models on the provided dataset.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "For this part we will be using the Universal Dependencies English Web Treebank data (v2.17 - 2025-11-15). The data is already split into training, development and test subsets.\n",
    "\n",
    "en_ewt-ud-train.conllu\n",
    "en_ewt-ud-dev.conllu\n",
    "en_ewt-ud-test.conllu\n",
    "\n",
    "Each one of these subsets contain words, grouped by sentences, each one of them labeled with the corresponding POS tag. After downloading the data, the following function can be used to load each one of the datasets individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232306ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 16:03:57.397521: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 16:03:57.435236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 16:03:58.395677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b80c76",
   "metadata": {},
   "source": [
    "**Task 1.1 - Train an LSTM-Based Model**\n",
    "\n",
    "    Train a sequence model (e.g. LSTM) on the training set.\n",
    "    Include an embedding layer. Pre-trained embeddings, such as Glove embeddings, are avaliable for download and can be used.\n",
    "    Output a POS tag per token using a softmax classifier.\n",
    "\n",
    "Evaluate your model on the test set\n",
    "\n",
    "    Report the global performance using Accuracy\n",
    "    Report the performance per-class using Precision, Recall, F1-score\n",
    "    \n",
    "Report training time, model size, and any hardware constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sentences: 12544 2001 2077\n",
      "Total sentences: 2001\n",
      "First 3 sentences:\n",
      "Sentence 1:\n",
      "  Words: ['From', 'the', 'AP', 'comes', 'this', 'story', ':']\n",
      "  POS tags: ['ADP', 'DET', 'PROPN', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "Sentence 2:\n",
      "  Words: ['President', 'Bush', 'on', 'Tuesday', 'nominated', 'two', 'individuals', 'to', 'replace', 'retiring', 'jurists', 'on', 'federal', 'courts', 'in', 'the', 'Washington', 'area', '.']\n",
      "  POS tags: ['PROPN', 'PROPN', 'ADP', 'PROPN', 'VERB', 'NUM', 'NOUN', 'PART', 'VERB', 'VERB', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'PROPN', 'NOUN', 'PUNCT']\n",
      "Sentence 3:\n",
      "  Words: ['Bush', 'nominated', 'Jennifer', 'M.', 'Anderson', 'for', 'a', '15', '-', 'year', 'term', 'as', 'associate', 'judge', 'of', 'the', 'Superior', 'Court', 'of', 'the', 'District', 'of', 'Columbia', ',', 'replacing', 'Steffen', 'W.', 'Graae', '.']\n",
      "  POS tags: ['PROPN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'ADP', 'DET', 'NUM', 'PUNCT', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'PROPN', 'ADP', 'DET', 'PROPN', 'ADP', 'PROPN', 'PUNCT', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# --- Funções de Leitura de Dados ---\n",
    "\n",
    "def read_conllu_file(filepath):\n",
    "    \"\"\"\n",
    "    Read a CoNLL-U format file and extract words and POS tags sentence by sentence.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CoNLL-U file\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries, each containing 'words' and 'pos_tags' lists for a sentence\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = {'words': [], 'pos_tags': []}\n",
    "    \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as data_file:\n",
    "        for line in data_file:\n",
    "            if line.startswith(\"#\"):\n",
    "                # Skip comment lines\n",
    "                pass\n",
    "            elif line.strip() == \"\":\n",
    "                # Empty line marks end of sentence\n",
    "                if current_sentence['words']:  # Only add non-empty sentences\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = {'words': [], 'pos_tags': []}\n",
    "            else:\n",
    "                # Parse the token line\n",
    "                fields = line.split(\"\\t\")\n",
    "                word, pos = fields[1], fields[3]\n",
    "                current_sentence['words'].append(word)\n",
    "                current_sentence['pos_tags'].append(pos)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "#load data\n",
    "TRAIN = \"./data/en_ewt-ud-train.conllu\"\n",
    "DEV = \"./data/en_ewt-ud-dev.conllu\"\n",
    "TEST = \"./data/en_ewt-ud-test.conllu\"\n",
    "\n",
    "# --- 1) Carregar Dados ---\n",
    "try:\n",
    "    train_sents = read_conllu_file(TRAIN)\n",
    "    dev_sents = read_conllu_file(DEV)\n",
    "    test_sents = read_conllu_file(TEST)\n",
    "    print(\"Loaded sentences:\", len(train_sents), len(dev_sents), len(test_sents))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erro: Ficheiro de dados não encontrado: {e.filename}. Certifique-se de que os ficheiros CoNLL-U estão em './data/'\")\n",
    "    exit()\n",
    "\n",
    "# Display preview\n",
    "print(f\"Total sentences: {len(dev_sents)}\")\n",
    "print(f\"First 3 sentences:\")\n",
    "for i, sent in enumerate(dev_sents[:3]):\n",
    "    print(f\"Sentence {i+1}:\")\n",
    "    print(f\"  Words: {sent['words']}\")\n",
    "    print(f\"  POS tags: {sent['pos_tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe7364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções de Loss e Métrica Personalizadas para Ignorar Padding ---\n",
    "\n",
    "# O valor que usamos para padding nos labels.\n",
    "# Deve ser um valor negativo ou um valor que não seja um índice de classe válido.\n",
    "PAD_VALUE = -100\n",
    "\n",
    "def masked_sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula a sparse_categorical_crossentropy ignorando os tokens de padding.\n",
    "    O padding é identificado pelo valor PAD_VALUE nos labels y_true.\n",
    "    \"\"\"\n",
    "    # 1. Criar a máscara: 1.0 onde o label não é PAD_VALUE, 0.0 onde é.\n",
    "    # y_true tem shape (batch_size, max_len).\n",
    "    mask = tf.cast(tf.not_equal(y_true, PAD_VALUE), tf.float32)\n",
    "    \n",
    "    # 2. Converter y_true para um tensor de inteiros (necessário para a loss).\n",
    "    # O Keras exige que os labels sejam >= 0. Vamos substituir PAD_VALUE por 0\n",
    "    # APENAS para o cálculo da loss, mas a máscara garante que o seu contributo é zero.\n",
    "    y_true_safe = tf.where(tf.equal(y_true, PAD_VALUE), tf.constant(0, dtype=y_true.dtype), y_true)\n",
    "    \n",
    "    # 3. Calcular a loss normal (por token).\n",
    "    # sparse_categorical_crossentropy espera y_true com shape (batch_size, max_len)\n",
    "    # e y_pred com shape (batch_size, max_len, num_classes).\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_safe, y_pred)\n",
    "    \n",
    "    # 4. Aplicar a máscara à loss.\n",
    "    masked_loss = loss * mask\n",
    "    \n",
    "    # 5. Normalizar a loss pelo número de tokens não-padding.\n",
    "    # Isto é crucial para que a loss não diminua artificialmente com o aumento do padding.\n",
    "    num_non_padded_tokens = tf.reduce_sum(mask)\n",
    "    \n",
    "    # Evitar divisão por zero\n",
    "    return tf.reduce_sum(masked_loss) / (num_non_padded_tokens + 1e-7)\n",
    "\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula a acurácia ignorando os tokens de padding.\n",
    "    \"\"\"\n",
    "    # 1. Criar a máscara.\n",
    "    mask = tf.cast(tf.not_equal(y_true, PAD_VALUE), tf.float32)\n",
    "    \n",
    "    # 2. Obter as classes previstas (índice da maior probabilidade).\n",
    "    y_pred_class = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n",
    "    \n",
    "    # 3. Converter y_true para um tensor de inteiros (para comparação).\n",
    "    y_true_int = tf.cast(y_true, tf.int32)\n",
    "    \n",
    "    # 4. Comparar previsões com labels verdadeiros.\n",
    "    matches = tf.cast(tf.equal(y_true_int, y_pred_class), tf.float32)\n",
    "    \n",
    "    # 5. Aplicar a máscara.\n",
    "    masked_matches = matches * mask\n",
    "    \n",
    "    # 6. Normalizar a acurácia pelo número de tokens não-padding.\n",
    "    num_non_padded_tokens = tf.reduce_sum(mask)\n",
    "    \n",
    "    # Evitar divisão por zero\n",
    "    return tf.reduce_sum(masked_matches) / (num_non_padded_tokens + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eab4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20203 num tags: 18\n",
      "Warning: GloVe file not found at ../Part1/data/wiki_giga_2024_300_MFT20_vectors_seed_2024_alpha_0.75_eta_0.05_combined.txt -> using random init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764868141.950386    1310 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-12-04 17:09:02.174897: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:41] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykernel_launcher.runfiles/cuda_nvdisasm\n",
      "  ipykernel_launcher.runfiles/nvidia_nvshmem\n",
      "  ipykern/cuda_nvcc\n",
      "  ipykern/cuda_nvdisasm\n",
      "  ipykern/nvidia_nvshmem\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /opt/cuda\n",
      "  /home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/tensorflow/python/platform/../../cuda\n",
      "  /home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/tensorflow/python/platform/../../../../../..\n",
      "  /home/ricadinho/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/tensorflow/python/platform/../../../../../../..\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2025-12-04 17:09:02.184591: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.186802: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.188843: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.190920: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.193468: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.196700: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.198290: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.200381: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.203314: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.205737: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.208561: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.210789: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.212458: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-12-04 17:09:02.663768: W external/local_xla/xla/service/gpu/llvm_gpu_backend/nvptx_backend.cc:110] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2025-12-04 17:09:02.663975: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:227] INTERNAL: Generating device code failed.\n",
      "2025-12-04 17:09:02.664724: W tensorflow/core/framework/op_kernel.cc:1842] UNKNOWN: JIT compilation failed.\n",
      "2025-12-04 17:09:02.664743: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__Sign_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sign] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     91\u001b[39m inp = Input(shape=(MAX_LEN,), dtype=\u001b[33m'\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m'\u001b[39m, name=\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m emb = Embedding(input_dim=vocab_size,\n\u001b[32m     93\u001b[39m                 output_dim=EMB_DIM,\n\u001b[32m     94\u001b[39m                 weights=[embedding_matrix],\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m                 trainable=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     98\u001b[39m                 )(inp)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m x = \u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbilstm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m out = TimeDistributed(Dense(num_tags, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m), name=\u001b[33m\"\u001b[39m\u001b[33mtag_out\u001b[39m\u001b[33m\"\u001b[39m)(x)\n\u001b[32m    103\u001b[39m model = Model(inputs=inp, outputs=out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cenas_universidade/2_ano/1_semestre/AAA/ree/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py:2421\u001b[39m, in \u001b[36msign\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2419\u001b[39m     x = tf.cast(x, \u001b[33m\"\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(tf.sign(x), ori_dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUnknownError\u001b[39m: {{function_node __wrapped__Sign_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sign] name: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# --- Configuração de Parâmetros ---\n",
    "#glove_path = \"../Part1/data/wiki_giga_2024_100_MFT20_vectors_seed_2024_alpha_0.75_eta_0.05.050_combined.txt\"\n",
    "#glove_path = \"../Part1/data/wiki_giga_2024_200_MFT20_vectors_seed_2024_alpha_0.75_eta_0.05_combined.txt\"\n",
    "glove_path = \"../Part1/data/wiki_giga_2024_300_MFT20_vectors_seed_2024_alpha_0.75_eta_0.05_combined.txt\"\n",
    "\n",
    "DIM = 300\n",
    "EMB_DIM = DIM\n",
    "MAX_LEN = DIM\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "PAD_VALUE = -100\n",
    "PAD_INDEX = 0 # Índice para o token <PAD> no word2idx\n",
    "\n",
    "\n",
    "# --- 2) Vocab / encoding / padding ---\n",
    "word_counts = Counter(w for s in train_sents for w in s['words'])\n",
    "word2idx = {\"<PAD>\":PAD_INDEX, \"<UNK>\":1}\n",
    "for w,_ in word_counts.items():\n",
    "    if w not in word2idx:\n",
    "        word2idx[w] = len(word2idx)\n",
    "\n",
    "tags = sorted(list({t for s in train_sents for t in s['pos_tags']}))\n",
    "tag2idx = {t:i for i,t in enumerate(tags)}\n",
    "idx2tag = {i:t for t,i in tag2idx.items()}\n",
    "num_tags = len(tag2idx)\n",
    "vocab_size = len(word2idx)\n",
    "print(\"Vocab size:\", vocab_size, \"num tags:\", num_tags)\n",
    "\n",
    "def encode_sentences(sents, w2i, t2i):\n",
    "    X, y = [], []\n",
    "    for s in sents:\n",
    "        X.append([w2i.get(w, w2i[\"<UNK>\"]) for w in s['words']])\n",
    "        y.append([t2i[t] for t in s['pos_tags']])\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = encode_sentences(train_sents, word2idx, tag2idx)\n",
    "X_dev, y_dev = encode_sentences(dev_sents, word2idx, tag2idx)\n",
    "X_test, y_test = encode_sentences(test_sents, word2idx, tag2idx)\n",
    "\n",
    "# Padding dos inputs (X)\n",
    "X_train_p = pad_sequences(X_train, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_dev_p = pad_sequences(X_dev, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test_p = pad_sequences(X_test, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Padding dos labels (y) com o valor especial PAD_VALUE\n",
    "y_train_p = pad_sequences(y_train, maxlen=MAX_LEN, padding='post', truncating='post', value=PAD_VALUE)\n",
    "y_dev_p = pad_sequences(y_dev, maxlen=MAX_LEN, padding='post', truncating='post', value=PAD_VALUE)\n",
    "y_test_p = pad_sequences(y_test, maxlen=MAX_LEN, padding='post', truncating='post', value=PAD_VALUE)\n",
    "\n",
    "# Garante que os labels são int32 (necessário para Keras)\n",
    "y_train_sparse = y_train_p.astype(np.int32)\n",
    "y_dev_sparse = y_dev_p.astype(np.int32)\n",
    "y_test_sparse = y_test_p.astype(np.int32)\n",
    "\n",
    "# --- 3) Carregar GloVe e montar embedding_matrix ---\n",
    "rng = np.random.RandomState(12345)\n",
    "embedding_matrix = rng.normal(scale=0.6, size=(vocab_size, EMB_DIM)).astype(np.float32)\n",
    "embedding_matrix[PAD_INDEX] = np.zeros((EMB_DIM,), dtype=np.float32)\n",
    "\n",
    "if os.path.exists(glove_path):\n",
    "    wanted = set(word2idx.keys()) | set(w.lower() for w in word2idx.keys())\n",
    "    found = 0\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip().split(\" \")\n",
    "            word = parts[0]\n",
    "            if word not in wanted:\n",
    "                continue\n",
    "            vec = np.asarray(parts[1:], dtype=np.float32)\n",
    "            if vec.shape[0] != EMB_DIM:\n",
    "                continue\n",
    "\n",
    "            # Coloca em qualquer índice correspondente (case-sensitive then lowercase)\n",
    "            if word in word2idx:\n",
    "                embedding_matrix[word2idx[word]] = vec\n",
    "                found += 1\n",
    "            lower = word.lower()\n",
    "            if lower in word2idx and word2idx[lower] != word2idx.get(word): # Evitar contar duas vezes se word == lower\n",
    "                embedding_matrix[word2idx[lower]] = vec\n",
    "                found += 1\n",
    "    print(f\"GloVe: found {found} tokens from vocab and loaded into embedding_matrix\")\n",
    "else:\n",
    "    print(\"Warning: GloVe file not found at\", glove_path, \"-> using random init\")\n",
    "\n",
    "embedding_matrix[PAD_INDEX] = np.zeros((EMB_DIM,), dtype=np.float32) # Re-assert PAD row is zero\n",
    "\n",
    "# --- 4) Construir o modelo Keras com Embedding congelada ---\n",
    "inp = Input(shape=(MAX_LEN,), dtype='int32', name=\"input_ids\")\n",
    "emb = Embedding(input_dim=vocab_size,\n",
    "                output_dim=EMB_DIM,\n",
    "                weights=[embedding_matrix],\n",
    "                input_length=MAX_LEN,\n",
    "                mask_zero=True, # Importante para o Keras ignorar o padding no LSTM\n",
    "                trainable=False,\n",
    "                )(inp)\n",
    "\n",
    "x = Bidirectional(LSTM(128, return_sequences=True), name=\"bilstm\")(emb)\n",
    "out = TimeDistributed(Dense(num_tags, activation='softmax'), name=\"tag_out\")(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# --- COMPILAÇÃO COM LOSS E MÉTRICA PERSONALIZADAS ---\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=masked_sparse_categorical_crossentropy,\n",
    "              metrics=[masked_accuracy])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- 5) Treinar ---\n",
    "print(\"\\n--- INÍCIO DO TREINO (Com Loss e Métrica Corrigidas) ---\")\n",
    "start = time.time()\n",
    "history = model.fit(X_train_p, y_train_sparse,\n",
    "                    validation_data=(X_dev_p, y_dev_sparse),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE\n",
    "                    )\n",
    "train_time = time.time() - start\n",
    "print(f\"\\nTreino concluído em {train_time:.1f} s\")\n",
    "\n",
    "# --- 6) Avaliar no test set: obter previsões token-level e métricas por classe ---\n",
    "preds = model.predict(X_test_p, batch_size=BATCH_SIZE, verbose=0) # shape (N, MAX_LEN, num_tags)\n",
    "pred_labels = np.argmax(preds, axis=-1) # Flatten ignorando os PAD_VALUE tokens\n",
    "\n",
    "def flatten_preds_trues(preds_labels, true_padded, mask_value=PAD_VALUE):\n",
    "    \"\"\" Função original do utilizador para avaliação final, mantida. \"\"\"\n",
    "    pred_flat = []\n",
    "    true_flat = []\n",
    "    for p_seq, t_seq in zip(preds_labels, true_padded):\n",
    "        for p, t in zip(p_seq, t_seq):\n",
    "            if t == mask_value:\n",
    "                continue\n",
    "            pred_flat.append(int(p))\n",
    "            true_flat.append(int(t))\n",
    "    return pred_flat, true_flat\n",
    "\n",
    "pred_flat, true_flat = flatten_preds_trues(pred_labels, y_test_p, mask_value=PAD_VALUE)\n",
    "acc = accuracy_score(true_flat, pred_flat)\n",
    "print(f\"\\nTest Accuracy (token-level - avaliação final): {acc:.4f}\\n\")\n",
    "\n",
    "# O classification_report requer que os labels sejam 0-indexed, o que é o caso\n",
    "# porque o tag2idx começa em 0.\n",
    "print(\"Classification report (Precision/Recall/F1):\\n\")\n",
    "print(classification_report(true_flat, pred_flat, target_names=[idx2tag[i] for i in range(num_tags)], zero_division=0))\n",
    "\n",
    "# --- 7) Guardar modelo / embedding_matrix se quiseres ---\n",
    "model.save(\"pos_model_glove_frozen_corrected.h5\")\n",
    "np.save(f\"embedding_matrix_${DIM}d.npy\", embedding_matrix)\n",
    "print(\"Model e embedding matrix salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIM 100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history\n",
    "\n",
    "## --- 1. Plot Training & Validation Loss ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot for Loss\n",
    "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Evolution Over Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "## --- 2. Plot Training & Validation Accuracy ---\n",
    "\n",
    "# Subplot for Accuracy\n",
    "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
    "# NOTE: Use the exact name of your custom metric defined in model.compile()\n",
    "train_metric = 'masked_accuracy'\n",
    "val_metric = 'val_masked_accuracy'\n",
    "\n",
    "plt.plot(history.history[train_metric], label='Training Accuracy')\n",
    "plt.plot(history.history[val_metric], label='Validation Accuracy')\n",
    "plt.title('Accuracy Evolution Over Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout() # Adjusts subplots to fit in figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a783d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIM 200\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history\n",
    "\n",
    "## --- 1. Plot Training & Validation Loss ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot for Loss\n",
    "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Evolution Over Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "## --- 2. Plot Training & Validation Accuracy ---\n",
    "\n",
    "# Subplot for Accuracy\n",
    "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
    "# NOTE: Use the exact name of your custom metric defined in model.compile()\n",
    "train_metric = 'masked_accuracy'\n",
    "val_metric = 'val_masked_accuracy'\n",
    "\n",
    "plt.plot(history.history[train_metric], label='Training Accuracy')\n",
    "plt.plot(history.history[val_metric], label='Validation Accuracy')\n",
    "plt.title('Accuracy Evolution Over Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout() # Adjusts subplots to fit in figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIM 300\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history\n",
    "\n",
    "## --- 1. Plot Training & Validation Loss ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot for Loss\n",
    "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Evolution Over Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "## --- 2. Plot Training & Validation Accuracy ---\n",
    "\n",
    "# Subplot for Accuracy\n",
    "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
    "# NOTE: Use the exact name of your custom metric defined in model.compile()\n",
    "train_metric = 'masked_accuracy'\n",
    "val_metric = 'val_masked_accuracy'\n",
    "\n",
    "plt.plot(history.history[train_metric], label='Training Accuracy')\n",
    "plt.plot(history.history[val_metric], label='Validation Accuracy')\n",
    "plt.title('Accuracy Evolution Over Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout() # Adjusts subplots to fit in figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207842f",
   "metadata": {},
   "source": [
    "**Task 1.2 - Transformer-Based Encoder Model**\n",
    "\n",
    "    Choose an encoder-based model (e.g., DistilBERT, BERT, RoBERTa, NeoBERT, EuroBERT)\n",
    "    Ensure proper handling of subword tokenization (alignment between tokens and tags).\n",
    "    Fine-tune the model for token-level classification (POS tagging).\n",
    "\n",
    "Evaluate your model on the test set. Please take into account that the tokens being used by the model may not entirely correspond to existing the tokens\n",
    "\n",
    "    Report the global performance using Accuracy\n",
    "    Report the performance per-class using Precision, Recall, F1-score\n",
    "\n",
    "Report training time, model size, and any hardware constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1899423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing CoNLL-U files...\n",
      "Loaded: train=12544, dev=2001, test=2077\n",
      "Labels (17): ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and aligning labels...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 141\u001b[39m\n\u001b[32m    138\u001b[39m datasets = DatasetDict({\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m: hf_train, \u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m: hf_val, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: hf_test})\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Trainer (no compute_metrics here because we'll evaluate with sklearn after train)\u001b[39;00m\n\u001b[32m    159\u001b[39m trainer = Trainer(\n\u001b[32m    160\u001b[39m     model=model,\n\u001b[32m    161\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m     tokenizer=tokenizer,\n\u001b[32m    165\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# bert_finetune_and_eval_sklearn.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import random\n",
    "\n",
    "# -------------------------\n",
    "# Helpers: parse CoNLL-U\n",
    "# -------------------------\n",
    "def parse_conllu(path):\n",
    "    examples = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        upos = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\" or line.startswith(\"#\"):\n",
    "                if tokens:\n",
    "                    examples.append({\"tokens\": tokens, \"upos\": upos})\n",
    "                    tokens = []\n",
    "                    upos = []\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 10:\n",
    "                continue\n",
    "            idx, form, lemma, upos_tag, xpos, feats, head, deprel, deps, misc = parts\n",
    "            # skip multiword tokens and empty nodes\n",
    "            if \"-\" in idx or \".\" in idx:\n",
    "                continue\n",
    "            tokens.append(form)\n",
    "            upos.append(upos_tag)\n",
    "        if tokens:\n",
    "            examples.append({\"tokens\": tokens, \"upos\": upos})\n",
    "    return examples\n",
    "\n",
    "# -------------------------\n",
    "# Align labels to tokens (wordpiece)\n",
    "# -------------------------\n",
    "def align_labels_with_tokens(tokenizer, examples, label_to_id, max_length=128):\n",
    "    tokenized_inputs = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "    for ex in examples:\n",
    "        tokens = ex[\"tokens\"]\n",
    "        labels = ex[\"upos\"]\n",
    "        # tokenize with is_split_into_words\n",
    "        enc = tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        word_ids = enc.word_ids()\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(label_to_id[labels[word_idx]])\n",
    "            else:\n",
    "                # ignore subsequent subword tokens in loss\n",
    "                aligned_labels.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        tokenized_inputs[\"input_ids\"].append(enc[\"input_ids\"])\n",
    "        tokenized_inputs[\"attention_mask\"].append(enc[\"attention_mask\"])\n",
    "        tokenized_inputs[\"labels\"].append(aligned_labels)\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Paths - adjust if necessary\n",
    "train_file = TRAIN\n",
    "dev_file =  DEV\n",
    "test_file =  TEST\n",
    "\n",
    "# model/tokenizer settings\n",
    "model_name = \"bert-base-cased\"  # UD often benefits from cased tokenizer\n",
    "max_length = 128\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "epochs = 3\n",
    "output_dir = \"./out_bert_pos\"\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Parse datasets\n",
    "print(\"Parsing CoNLL-U files...\")\n",
    "train_examples = parse_conllu(train_file)\n",
    "dev_examples = parse_conllu(dev_file)\n",
    "test_examples = parse_conllu(test_file)\n",
    "print(f\"Loaded: train={len(train_examples)}, dev={len(dev_examples)}, test={len(test_examples)}\")\n",
    " \n",
    "# Build label list from all splits\n",
    "counter = Counter()\n",
    "for ex in (train_examples + dev_examples + test_examples):\n",
    "    counter.update(ex[\"upos\"])\n",
    "label_list = sorted(counter.keys())\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "id_to_label = {i: l for l, i in label_to_id.items()}\n",
    "print(f\"Labels ({len(label_list)}): {label_list}\")\n",
    "\n",
    "# Tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    ")\n",
    "\n",
    "# Align labels to tokenizer outputs\n",
    "print(\"Tokenizing and aligning labels...\")\n",
    "tokenized_train = align_labels_with_tokens(tokenizer, train_examples, label_to_id, max_length=max_length)\n",
    "tokenized_val   = align_labels_with_tokens(tokenizer, dev_examples,   label_to_id, max_length=max_length)\n",
    "tokenized_test  = align_labels_with_tokens(tokenizer, test_examples,  label_to_id, max_length=max_length)\n",
    "\n",
    "# Convert to HF Dataset objects\n",
    "hf_train = Dataset.from_dict(tokenized_train)\n",
    "hf_val   = Dataset.from_dict(tokenized_val)\n",
    "hf_test  = Dataset.from_dict(tokenized_test)\n",
    "datasets = DatasetDict({\"train\": hf_train, \"validation\": hf_val, \"test\": hf_test})\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=200,\n",
    "    save_total_limit=2,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "# Trainer (no compute_metrics here because we'll evaluate with sklearn after train)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model & tokenizer saved to {output_dir}\")\n",
    " \n",
    "# -------------------------\n",
    "# Predict on test set\n",
    "# -------------------------\n",
    "print(\"Running predictions on test set...\")\n",
    "raw_pred = trainer.predict(datasets[\"test\"])\n",
    "logits = raw_pred.predictions  # shape (N, seq_len, n_labels)\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "labels = raw_pred.label_ids  # -100 where ignored\n",
    "\n",
    "# Flatten predictions & labels, ignoring -100 positions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(labels.shape[0]):\n",
    "    for j in range(labels.shape[1]):\n",
    "        lab = labels[i, j]\n",
    "        if lab == -100:\n",
    "            continue\n",
    "        y_true.append(id_to_label[int(lab)])\n",
    "        y_pred.append(id_to_label[int(preds[i, j])])\n",
    "\n",
    "# Global accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nGlobal Accuracy on test set: {acc:.4f}\")\n",
    "\n",
    "# Per-class precision/recall/f1 & support\n",
    "# Convert to integer ids for sklearn functions\n",
    "y_true_ids = [label_to_id[l] for l in y_true]\n",
    "y_pred_ids = [label_to_id[l] for l in y_pred]\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true_ids, y_pred_ids, labels=list(range(len(label_list))), zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nPer-class performance:\")\n",
    "print(\"{:10s} {:8s} {:8s} {:8s} {:8s}\".format(\"LABEL\", \"PREC\", \"RECL\", \"F1\", \"SUPPORT\"))\n",
    "for i, lab in enumerate(label_list):\n",
    "    print(f\"{lab:10s} {precision[i]:8.4f} {recall[i]:8.4f} {f1[i]:8.4f} {support[i]:8d}\")\n",
    "\n",
    "# More readable classification_report\n",
    "print(\"\\nClassification report (sklearn):\\n\")\n",
    "print(classification_report(y_true_ids, y_pred_ids, labels=list(range(len(label_list))), target_names=label_list, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebe3c6",
   "metadata": {},
   "source": [
    "**Task 1.3 - Use LLMs to perform the task in the test set (optional, only if you have time)**\n",
    "\n",
    "    Choose an existing LLM of your choice (e.g., ChatGPT)\n",
    "    Define a prompt and perform the classification.\n",
    "    Report the performance of the model, and compare it with your previous models.\n",
    "    \n",
    "**Comparison and Analysis**\n",
    "\n",
    "    Compare the performance of the previous models, in terms of:\n",
    "        Quantitative performance (metrics)\n",
    "        Qualitative behavior (e.g., errors, generalization)\n",
    "        Computational efficiency and training stability\n",
    "\n",
    "    Discuss potential reasons for performance differences.\n",
    "    Optionally visualize:\n",
    "        Confusion matrices\n",
    "        Learning curves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
